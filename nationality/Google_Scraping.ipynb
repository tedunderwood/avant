{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages, open original dataframe, get only relevant data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.parse\n",
    "import time\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Open the dataframe\n",
    "\n",
    "df_final_corpus = pd.read_csv(\"./finalcorpus.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>hathi_author</th>\n",
       "      <th>hathi_title</th>\n",
       "      <th>authordate</th>\n",
       "      <th>birthyear</th>\n",
       "      <th>deathyear</th>\n",
       "      <th>chi_date</th>\n",
       "      <th>ukw_date</th>\n",
       "      <th>copyright_date</th>\n",
       "      <th>firstpub</th>\n",
       "      <th>...</th>\n",
       "      <th>distances</th>\n",
       "      <th>copyright_corpus</th>\n",
       "      <th>manual_corpus</th>\n",
       "      <th>us_national</th>\n",
       "      <th>pubdate_known</th>\n",
       "      <th>authof3ormore</th>\n",
       "      <th>tokens</th>\n",
       "      <th>pagesinchunk</th>\n",
       "      <th>tokensperpage</th>\n",
       "      <th>omnibus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>loc.ark+=13960=t49p3qv8g</td>\n",
       "      <td>Thwing, Edward P[ayson]</td>\n",
       "      <td>Outdoor life in Europe, sketches of men and ma...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1880</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>45865</td>\n",
       "      <td>54</td>\n",
       "      <td>849.352</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>loc.ark+=13960=t7wm1fd5j</td>\n",
       "      <td>Jones, Joseph</td>\n",
       "      <td>Major Jones's travels</td>\n",
       "      <td>1812-1882.</td>\n",
       "      <td>1812.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1880</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>42135</td>\n",
       "      <td>204</td>\n",
       "      <td>206.544</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nyp.33433081882650</td>\n",
       "      <td>Allan-Olney, Mary</td>\n",
       "      <td>The new Virginians</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1880</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>32052</td>\n",
       "      <td>244</td>\n",
       "      <td>131.361</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uva.x030742146</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Growing world; or, Progress of civilizatio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1880</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>374115</td>\n",
       "      <td>420</td>\n",
       "      <td>890.750</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nyp.33433074386792</td>\n",
       "      <td>of Samosata. Lucian</td>\n",
       "      <td>A traveller's true tale</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1880</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>11848</td>\n",
       "      <td>128</td>\n",
       "      <td>92.562</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      docid             hathi_author  \\\n",
       "0  loc.ark+=13960=t49p3qv8g  Thwing, Edward P[ayson]   \n",
       "1  loc.ark+=13960=t7wm1fd5j            Jones, Joseph   \n",
       "2        nyp.33433081882650        Allan-Olney, Mary   \n",
       "3            uva.x030742146                      NaN   \n",
       "4        nyp.33433074386792      of Samosata. Lucian   \n",
       "\n",
       "                                         hathi_title  authordate  birthyear  \\\n",
       "0  Outdoor life in Europe, sketches of men and ma...         NaN        NaN   \n",
       "1                              Major Jones's travels  1812-1882.     1812.0   \n",
       "2                                 The new Virginians         NaN        NaN   \n",
       "3  The Growing world; or, Progress of civilizatio...         NaN        NaN   \n",
       "4                            A traveller's true tale         NaN        NaN   \n",
       "\n",
       "   deathyear  chi_date  ukw_date  copyright_date  firstpub  ...  distances  \\\n",
       "0        NaN       NaN       NaN             NaN      1880  ...        NaN   \n",
       "1        NaN       NaN       NaN             NaN      1880  ...        NaN   \n",
       "2        NaN       NaN       NaN             NaN      1880  ...        NaN   \n",
       "3        NaN       NaN       NaN             NaN      1880  ...        NaN   \n",
       "4        NaN       NaN       NaN             NaN      1880  ...        NaN   \n",
       "\n",
       "  copyright_corpus  manual_corpus  us_national  pubdate_known  authof3ormore  \\\n",
       "0            False          False        False          False          False   \n",
       "1            False          False        False          False          False   \n",
       "2            False          False        False          False          False   \n",
       "3            False          False        False          False          False   \n",
       "4            False          False        False          False          False   \n",
       "\n",
       "   tokens  pagesinchunk  tokensperpage  omnibus  \n",
       "0   45865            54        849.352    False  \n",
       "1   42135           204        206.544    False  \n",
       "2   32052           244        131.361    False  \n",
       "3  374115           420        890.750    False  \n",
       "4   11848           128         92.562    False  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hathi_author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thwing, Edward P[ayson]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jones, Joseph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Allan-Olney, Mary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>of Samosata. Lucian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              hathi_author\n",
       "0  Thwing, Edward P[ayson]\n",
       "1            Jones, Joseph\n",
       "2        Allan-Olney, Mary\n",
       "3                      NaN\n",
       "4      of Samosata. Lucian"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's take only unique authors\n",
    "\n",
    "unique_authors = df_final_corpus.hathi_author.unique()\n",
    "authors = pd.DataFrame(unique_authors, columns=[\"hathi_author\"])\n",
    "authors.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google and Wiki scraping, the creation of the preliminary dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "194it [13:15,  4.10s/it]\n"
     ]
    }
   ],
   "source": [
    "authors = pd.DataFrame(unique_authors, columns=[\"hathi_author\"])\n",
    "#Let's scrape and parse\n",
    "# Google likes to limit the automatic generation of queries, so we should define the time.sleep period\n",
    "author = []\n",
    "clean_name = []\n",
    "google = []\n",
    "wiki = []\n",
    "wiki_natio = []\n",
    "wiki_link = []\n",
    "\n",
    "#I limited the df up to 1000 entries for now\n",
    "for index, row in tqdm(authors[:1000].iterrows()):  \n",
    "    if isinstance(row[\"hathi_author\"], str):\n",
    "        \n",
    "        #append the author's name to our df\n",
    "        author.append(row[\"hathi_author\"])\n",
    "        \n",
    "        #let's clean the name -> this step is not a necessary one, but it can improve our query results\n",
    "        surname_name = row[\"hathi_author\"].split(',')\n",
    "        clean_surname_name = [str(re.sub(\"\\(|\\)\", \"\", re.search(\"\\(.+\\)\", re.sub(\"\\[|\\]\", \"\", surname_name[1])).group(0))) + \" \" + surname_name[0] \\\n",
    "                if len(surname_name) > 1 and \"(\" in surname_name[1]\\\n",
    "                else re.sub(\"\\[|\\]\", \"\", ''.join(surname_name))]\n",
    "        clean_name.append(clean_surname_name[0])\n",
    "        \n",
    "        \n",
    "        #let's create a google query and get google results\n",
    "        query = clean_surname_name[0] + \"writer \"\n",
    "        query = urllib.parse.quote_plus(query).lower()\n",
    "        response = requests.get(\"https://www.google.com/search?q=\" + query)\n",
    "        response.encoding = 'utf8'\n",
    "        html = response.text\n",
    "        \n",
    "        #the next commented line is an optional one, in general it takes less than a sec to scrape and parse everthing, but here it will take 2 sec\n",
    "#         time.sleep(2) \n",
    "        \n",
    "        soup = BeautifulSoup(html)\n",
    "        \n",
    "        #let's check if there's a window with a brief info about an author and their nationality\n",
    "        cur_google_length = len(google)\n",
    "        if soup.find( 'div', class_=\"BNeawe tAd8D AP7Wnd\"): \n",
    "            brief_info = soup.find( 'div', class_=\"BNeawe tAd8D AP7Wnd\")\n",
    "            nationality = brief_info.text\n",
    "            \n",
    "            if len(nationality) > 0:\n",
    "                doc = nlp(nationality)\n",
    "                for ent in doc.ents:\n",
    "                    #if we find the window, let's check whether a nationality is indicated in it\n",
    "                    if ent.label_ == \"NORP\" or ent.label_ == \"LANGUAGE\":\n",
    "            \n",
    "                        google.append(str(ent))\n",
    "                        break\n",
    "                            \n",
    "        if len(google) == cur_google_length:\n",
    "            google.append(None)\n",
    "\n",
    "        #now let's look at the links google provides us with\n",
    "        heading_object=soup.find_all( 'a' )\n",
    "        \n",
    "        \n",
    "        cur_wiki_length = len(wiki)\n",
    "        cur_wiki_natio_length = len(wiki_natio)\n",
    "        cur_wiki_link_length = len(wiki_link)\n",
    "        \n",
    "        for info in heading_object:\n",
    "            \n",
    "            #here we check if there's a Wikipedia link among all the links\n",
    "            if \"Wikipedia\" in info.text:\n",
    "                link = info[\"href\"]\n",
    "                if link[link.index(\"https://\"):link.index(\"&sa\")]:\n",
    "                    link = link[link.index(\"https://\"):link.index(\"&sa\")]\n",
    "                else:\n",
    "                    link = link[link.index(\"https://\"):]\n",
    "                    \n",
    "                link = urllib.parse.unquote(urllib.parse.unquote(link))\n",
    "                wiki_link.append(link)\n",
    "\n",
    "                response_wiki = requests.get(link)\n",
    "                response_wiki.encoding = 'utf8'\n",
    "                html_wiki = response_wiki.text\n",
    "                soup_wiki = BeautifulSoup(html_wiki)\n",
    "                \n",
    "                #sometimes there's a specific line with a nationality info, so let's check if it's on the page\n",
    "                if soup_wiki.find(\"td\", class_ = 'infobox-data category'):\n",
    "                    natio = soup_wiki.find(\"td\", class_ = 'infobox-data category')\n",
    "                    doc = nlp(natio.text)\n",
    "                    nationality_found = False\n",
    "                    for ent in doc.ents:\n",
    "                        if ent.label_ == \"NORP\" or ent.label_ == \"LANGUAGE\":\n",
    "                            wiki_natio.append(str(ent))\n",
    "                            break\n",
    "                    \n",
    "                \n",
    "                #in addition, let's take three first paragraphs of the page, where the basic info is\n",
    "                \n",
    "                page = soup_wiki.find_all('p')[:3]\n",
    "                \n",
    "                doc = nlp(''.join([paragraph.get_text() for paragraph in page]))\n",
    "\n",
    "                nationalities = []\n",
    "                \n",
    "                #let's check again if there's a nationality\n",
    "                for ent in doc.ents:\n",
    "                    if ent.label_ == \"NORP\" or ent.label_ == \"LANGUAGE\":\n",
    "                        nationalities.append(str(ent))\n",
    "                        break\n",
    "                if len(nationalities)>0:\n",
    "                    wiki.append(nationalities[0])\n",
    "                break\n",
    "        \n",
    "        if len(wiki_natio) == cur_wiki_natio_length:\n",
    "            wiki_natio.append(None)            \n",
    "        if len(wiki) == cur_wiki_length:\n",
    "            wiki.append(None)\n",
    "        if len(wiki_link) == cur_wiki_link_length:\n",
    "            wiki_link.append(None)\n",
    "            \n",
    "        time.sleep(3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's combine all the info\n",
    "df_nationalities = pd.DataFrame()\n",
    "\n",
    "df_nationalities[\"Author\"] = author\n",
    "df_nationalities[\"Clean_name\"] = clean_name\n",
    "df_nationalities[\"Google\"] = google\n",
    "df_nationalities[\"Wiki_par\"] = wiki\n",
    "df_nationalities[\"Wiki_natio\"] = wiki_natio\n",
    "df_nationalities[\"Wiki_link\"] = wiki_link\n",
    "\n",
    "df_nationalities.loc[:,'Nationality'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a column \"Nationality\" and \"sum up\" all the results from the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#it is necessary to feel out the final column about nationality based on several factors\n",
    "\n",
    "for index, row in df_nationalities.iterrows():\n",
    "    \n",
    "    if row['Google'] is None and row['Wiki_par'] == row[\"Wiki_natio\"]:\n",
    "        df_nationalities.at[index,\"Nationality\"] = row['Wiki_natio']\n",
    "        \n",
    "    elif row['Google'] is None and row['Wiki_natio'] is None:\n",
    "        df_nationalities.at[index,\"Nationality\"] = row['Wiki_par']\n",
    "        \n",
    "    elif row['Google'] is None and row['Wiki_par'] is None:\n",
    "        df_nationalities.at[index,\"Nationality\"] = row['Wiki_natio']\n",
    "        \n",
    "    elif row['Google'] is not None and row['Wiki_par'] is not None and row['Wiki_natio'] is not None:\n",
    "        df_nationalities.at[index,\"Nationality\"] = row['Wiki_natio']\n",
    "        \n",
    "    elif row['Google'] is None and row['Wiki_par'] is not None and row[\"Wiki_natio\"] is not None and row['Wiki_par']!= row[\"Wiki_natio\"]:\n",
    "        df_nationalities.at[index,\"Nationality\"] = row['Wiki_natio']\n",
    "    \n",
    "    elif row['Google'] is None and row[\"Wiki_natio\"] is not None:\n",
    "        df_nationalities.at[index,\"Nationality\"] = row['Wiki_natio']\n",
    "        \n",
    "    else:\n",
    "        df_nationalities.at[index,\"Nationality\"] = row['Google']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Clean_name</th>\n",
       "      <th>Google</th>\n",
       "      <th>Wiki_par</th>\n",
       "      <th>Wiki_natio</th>\n",
       "      <th>Wiki_link</th>\n",
       "      <th>Nationality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thwing, Edward P[ayson]</td>\n",
       "      <td>Thwing Edward Payson</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jones, Joseph</td>\n",
       "      <td>Jones Joseph</td>\n",
       "      <td>American</td>\n",
       "      <td>American</td>\n",
       "      <td>None</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Joseph_R._Jones</td>\n",
       "      <td>American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Allan-Olney, Mary</td>\n",
       "      <td>Allan-Olney Mary</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of Samosata. Lucian</td>\n",
       "      <td>of Samosata. Lucian</td>\n",
       "      <td>None</td>\n",
       "      <td>Greek</td>\n",
       "      <td>None</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Lucian</td>\n",
       "      <td>Greek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arnold, Matthew</td>\n",
       "      <td>Arnold Matthew</td>\n",
       "      <td>English</td>\n",
       "      <td>English</td>\n",
       "      <td>British</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Matthew_Arnold</td>\n",
       "      <td>British</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>Lynch, Lawrence L</td>\n",
       "      <td>Lynch Lawrence L</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>Halstead, Ada L</td>\n",
       "      <td>Halstead Ada L</td>\n",
       "      <td>American</td>\n",
       "      <td>American</td>\n",
       "      <td>None</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Halsted_Sullivan</td>\n",
       "      <td>American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>Libbey, Laura Jean</td>\n",
       "      <td>Libbey Laura Jean</td>\n",
       "      <td>American</td>\n",
       "      <td>American</td>\n",
       "      <td>None</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Laura_Jean_Libbey</td>\n",
       "      <td>American</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>Shand, Alexander Innes</td>\n",
       "      <td>Shand Alexander Innes</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Alexander_Shand</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>Coxon, Ethel</td>\n",
       "      <td>Coxon Ethel</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>805 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Author             Clean_name    Google  Wiki_par  \\\n",
       "0    Thwing, Edward P[ayson]   Thwing Edward Payson      None      None   \n",
       "1              Jones, Joseph           Jones Joseph  American  American   \n",
       "2          Allan-Olney, Mary       Allan-Olney Mary      None      None   \n",
       "3        of Samosata. Lucian    of Samosata. Lucian      None     Greek   \n",
       "4            Arnold, Matthew         Arnold Matthew   English   English   \n",
       "..                       ...                    ...       ...       ...   \n",
       "800        Lynch, Lawrence L       Lynch Lawrence L      None      None   \n",
       "801          Halstead, Ada L         Halstead Ada L  American  American   \n",
       "802       Libbey, Laura Jean      Libbey Laura Jean  American  American   \n",
       "803   Shand, Alexander Innes  Shand Alexander Innes      None      None   \n",
       "804             Coxon, Ethel            Coxon Ethel      None      None   \n",
       "\n",
       "    Wiki_natio                                        Wiki_link Nationality  \n",
       "0         None                                             None        None  \n",
       "1         None    https://en.wikipedia.org/wiki/Joseph_R._Jones    American  \n",
       "2         None                                             None        None  \n",
       "3         None             https://en.wikipedia.org/wiki/Lucian       Greek  \n",
       "4      British     https://en.wikipedia.org/wiki/Matthew_Arnold     British  \n",
       "..         ...                                              ...         ...  \n",
       "800       None                                             None        None  \n",
       "801       None   https://en.wikipedia.org/wiki/Halsted_Sullivan    American  \n",
       "802       None  https://en.wikipedia.org/wiki/Laura_Jean_Libbey    American  \n",
       "803       None    https://en.wikipedia.org/wiki/Alexander_Shand        None  \n",
       "804       None                                             None        None  \n",
       "\n",
       "[805 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #Voila!\n",
    "df_nationalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's check the count of None-s\n",
    "df_nationalities[\"Nationality\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's save\n",
    "df_nationalities.to_csv(\"./nationalities.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
